{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 깊게 짜보기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리를 임포트합니다.\n",
    "import pandas as pd  # 데이터 조작 및 분석을 위한 라이브러리\n",
    "import numpy as np  # 수치 계산을 위한 라이브러리\n",
    "import wfdb  # 심전도 데이터를 읽기 위한 라이브러리\n",
    "import ast  # 문자열 형태의 파이썬 표현식을 파싱하기 위한 라이브러리\n",
    "from tqdm import tqdm  # 반복 작업의 진행 상황을 시각적으로 표시하기 위한 라이브러리\n",
    "import warnings; warnings.filterwarnings('ignore')  # 경고 메시지를 무시하기 위한 설정\n",
    "from IPython.display import display  # Jupyter 노트북에서 데이터를 깔끔하게 보여주기 위한 함수\n",
    "from glob import glob # 하위 디렉토리에 파일을 가져와서 다루기위한 라이브러리 \n",
    "import os # 현재 워킹디렉토리의 경로와 파일을 다루기 위한 라이브러리 \n",
    "import h5py #.h5파일을 다루기 위한 라이브러리 \n",
    "import gc #가비치 컬렉터를 다루는 라이브러리\n",
    "import random\n",
    "\n",
    "\n",
    "# 데이터 시각화를 위한 라이브러리를 임포트합니다.\n",
    "import matplotlib.pyplot as plt  # 그래프를 그리기 위한 라이브러리\n",
    "import seaborn as sns  # matplotlib 기반의 고급 시각화 라이브러리\n",
    "\n",
    "#머신러닝을 위한 scikit-learn 임포트 \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report \n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# 파이토치를 위한 라이브러리 임포트 \n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset # 텐서데이터셋\n",
    "import torch.optim as optim\n",
    "\n",
    "# 평가 지표 \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_recall_curve, \n",
    "    precision_score, recall_score, f1_score, confusion_matrix, roc_curve, average_precision_score\n",
    ")\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FixedLocator\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import json\n",
    "import yaml\n",
    "import random\n",
    "import wandb\n",
    "import ast\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모델 시드 고정 \n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # 멀티 GPU를 사용하는 경우\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ptb,sph데이터 \n",
    "\n",
    "# 데이터 프레임 로드\n",
    "path = './ptb_xl_data/'\n",
    "df_ptb = pd.read_csv(path + 'ptbxl_database.csv', index_col='ecg_id')\n",
    "df_sph = pd.read_csv(\"./sph_data/metadata.csv\")\n",
    "\n",
    "# str (문자열) 코드를 딕셔너리로 변환 \n",
    "df_ptb.scp_codes = df_ptb.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# 딕셔너리에서 라벨 추출 ()\n",
    "df_ptb.scp_codes = df_ptb.scp_codes.apply(lambda x: list(x.keys()))\n",
    "\n",
    "# 심방세동 라벨 컬럼 생성 (정답 컬럼)\n",
    "df_ptb['label'] = df_ptb.scp_codes.apply(lambda arr: 1 if 'AFIB' in arr else 0)\n",
    "\n",
    "# 'AHA_Code' 컬럼의 각 값에 대해 '50'이 포함되어 있는지 확인하고, 'label' 컬럼 생성\n",
    "def check_contains_50(code):\n",
    "    # 공백을 없애고, ';' 또는 '+'로 분리\n",
    "    numbers = code.replace(' ', '').replace('+', ';').split(';')\n",
    "    # '50'이 포함되어 있는지 확인\n",
    "    return '50' in numbers\n",
    "# 'label' 컬럼 생성\n",
    "df_sph['label'] = df_sph['AHA_Code'].apply(check_contains_50).astype(int)\n",
    "\n",
    "\n",
    "## 보경님 코드를 이용한 전처리 \n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "# custom_file 폴더에서 lead1_signals 데이터 로드\n",
    "lead1_signals = np.load('./custom_file/annie_ptb_xl_lead1.npy')\n",
    "\n",
    "\n",
    "# 레이블 데이터 로드\n",
    "labels = df_ptb['label'].values\n",
    "\n",
    "lead1_signals_float=lead1_signals.astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "# 데이터 정규화\n",
    "lead1_signals_normalized = (lead1_signals_float - lead1_signals_float.mean()) / (lead1_signals_float.std()+1e-7)\n",
    "\n",
    "\n",
    "# 데이터셋을 텐서로 변환\n",
    "X = torch.Tensor(lead1_signals_normalized)\n",
    "y = torch.Tensor(labels).long()  \n",
    "\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "# 채널 수를 1로 추가_GOOD\n",
    "X_train = X_train.unsqueeze(1)\n",
    "X_val = X_val.unsqueeze(1)\n",
    "X_test = X_test.unsqueeze(1)\n",
    "\n",
    "\n",
    "# DataLoader 생성\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "val_data = TensorDataset(X_val, y_val)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기존 모델 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 충원님 코드\n",
    "\n",
    "class Custom1DCNN1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Custom1DCNN1, self).__init__()\n",
    "\n",
    "        # Convolutional Blocks\n",
    "        self.conv1 = nn.Conv1d(1, 32, kernel_size=5)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(32, 32, kernel_size=5)\n",
    "        self.maxpool2 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(32, 64, kernel_size=5)\n",
    "        self.maxpool3 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.conv4 = nn.Conv1d(64, 64, kernel_size=5)\n",
    "        self.maxpool4 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.conv5 = nn.Conv1d(64, 128, kernel_size=5)\n",
    "        self.maxpool5 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.conv6 = nn.Conv1d(128, 128, kernel_size=5)\n",
    "        self.maxpool6 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "\n",
    "        self.conv7 = nn.Conv1d(128, 256, kernel_size=5)\n",
    "        self.maxpool7 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.conv8 = nn.Conv1d(256, 256, kernel_size=5)\n",
    "        self.maxpool8 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        self.conv9 = nn.Conv1d(256, 512, kernel_size=5)\n",
    "        self.maxpool9 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "\n",
    "        self.conv10 = nn.Conv1d(512, 512, kernel_size=5)\n",
    "\n",
    "        # Fully Connected Blocks\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.dense1 = nn.Linear(512, 128)\n",
    "        self.batch_norm_dense1 = nn.BatchNorm1d(128)  # BatchNorm1d for Dense1\n",
    "        self.dropout4 = nn.Dropout(0.5)\n",
    "\n",
    "        self.dense2 = nn.Linear(128, 32)\n",
    "        self.batch_norm_dense2 = nn.BatchNorm1d(32)  # BatchNorm1d for Dense2\n",
    "\n",
    "        self.dense3 = nn.Linear(32, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional Blocks\n",
    "        x = self.maxpool1(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.maxpool2(self.relu(self.conv2(x)))\n",
    "        x = self.maxpool3(self.relu(self.conv3(x)))\n",
    "        x = self.maxpool4(self.relu(self.conv4(x)))\n",
    "        x = self.maxpool5(self.relu(self.conv5(x)))\n",
    "        x = self.maxpool6(self.relu(self.conv6(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.maxpool7(self.relu(self.conv7(x)))\n",
    "        x = self.maxpool8(self.relu(self.conv8(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.maxpool9(self.relu(self.conv9(x)))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.conv10(x)\n",
    "\n",
    "        # Fully Connected Blocks\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout4(self.relu(self.batch_norm_dense1(self.dense1(x))))\n",
    "        x = self.relu(self.batch_norm_dense2(self.dense2(x)))\n",
    "        x = self.dense3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 좀더 깊게 짠 모델 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom1DCNN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Custom1DCNN2, self).__init__()\n",
    "\n",
    "        # Convolutional Blocks\n",
    "        self.conv1 = nn.Conv1d(1, 32, kernel_size=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(32, 32, kernel_size=2)\n",
    "        self.maxpool2 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(32, 64, kernel_size=2)\n",
    "        self.maxpool3 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.conv4 = nn.Conv1d(64, 64, kernel_size=2)\n",
    "        self.maxpool4 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.conv5 = nn.Conv1d(64, 128, kernel_size=2)\n",
    "        self.maxpool5 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.conv6 = nn.Conv1d(128, 128, kernel_size=2)\n",
    "        self.maxpool6 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "\n",
    "        self.conv7 = nn.Conv1d(128, 256, kernel_size=2)\n",
    "        self.maxpool7 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.conv8 = nn.Conv1d(256, 256, kernel_size=2)\n",
    "        self.maxpool8 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        self.conv9 = nn.Conv1d(256, 512, kernel_size=2)\n",
    "        self.maxpool9 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "\n",
    "        self.conv10 = nn.Conv1d(512, 512, kernel_size=2)\n",
    "        self.maxpool10 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv11 = nn.Conv1d(512, 1024, kernel_size=2)\n",
    "        self.maxpool11 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.dropout4 = nn.Dropout(0.5)\n",
    "        self.conv12 = nn.Conv1d(1024, 1024, kernel_size=1)\n",
    "\n",
    "        # Fully Connected Blocks\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.dense1 = nn.Linear(1024, 512)\n",
    "        \n",
    "        self.batch_norm_dense1 = nn.BatchNorm1d(512)  # BatchNorm1d for Dense1\n",
    "        self.dropout5 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.dense2 = nn.Linear(512, 128)\n",
    "        \n",
    "        self.batch_norm_dense2 = nn.BatchNorm1d(128)  # BatchNorm1d for Dense1\n",
    "        self.dropout6 = nn.Dropout(0.5)\n",
    "\n",
    "        self.dense3 = nn.Linear(128, 32)\n",
    "        self.batch_norm_dense3 = nn.BatchNorm1d(32)  # BatchNorm1d for Dense2\n",
    "\n",
    "        self.dense4 = nn.Linear(32, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional Blocks\n",
    "        x = self.maxpool1(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.maxpool2(self.relu(self.conv2(x)))\n",
    "        x = self.maxpool3(self.relu(self.conv3(x)))\n",
    "        x = self.maxpool4(self.relu(self.conv4(x)))\n",
    "        x = self.maxpool5(self.relu(self.conv5(x)))\n",
    "        x = self.maxpool6(self.relu(self.conv6(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.maxpool7(self.relu(self.conv7(x)))\n",
    "        x = self.maxpool8(self.relu(self.conv8(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.maxpool9(self.relu(self.conv9(x)))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.maxpool10(self.relu(self.conv10(x)))\n",
    "        x = self.maxpool11(self.relu(self.conv11(x)))\n",
    "        x = self.dropout4(x)\n",
    "        x = self.conv12(x)\n",
    "\n",
    "        # Fully Connected Blocks\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout5(self.relu(self.batch_norm_dense1(self.dense1(x))))\n",
    "        x = self.relu(self.batch_norm_dense2(self.dense2(x)))\n",
    "        x = self.dropout6(self.relu(self.batch_norm_dense3(self.dense3(x))))\n",
    "        x = self.dense4(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conv1 = nn.Conv1d(1, 32, kernel_size=2)\n",
    "bn1 = nn.BatchNorm1d(32)\n",
    "relu = nn.ReLU()\n",
    "maxpool1 = nn.MaxPool1d(2)\n",
    "conv2 = nn.Conv1d(32, 32, kernel_size=2)\n",
    "maxpool2 = nn.MaxPool1d(2)\n",
    "\n",
    "conv3 = nn.Conv1d(32, 64, kernel_size=2)\n",
    "maxpool3 = nn.MaxPool1d(2)\n",
    "\n",
    "conv4 = nn.Conv1d(64, 64, kernel_size=2)\n",
    "maxpool4 = nn.MaxPool1d(2)\n",
    "\n",
    "conv5 = nn.Conv1d(64, 128, kernel_size=2)\n",
    "maxpool5 = nn.MaxPool1d(2)\n",
    "\n",
    "conv6 = nn.Conv1d(128, 128, kernel_size=2)\n",
    "maxpool6 = nn.MaxPool1d(2)\n",
    "\n",
    "dropout1 = nn.Dropout(0.5)\n",
    "\n",
    "conv7 = nn.Conv1d(128, 256, kernel_size=2)\n",
    "maxpool7 = nn.MaxPool1d(2)\n",
    "\n",
    "conv8 = nn.Conv1d(256, 256, kernel_size=2)\n",
    "maxpool8 = nn.MaxPool1d(2)\n",
    "\n",
    "dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "conv9 = nn.Conv1d(256, 512, kernel_size=2)\n",
    "maxpool9 = nn.MaxPool1d(2)\n",
    "\n",
    "dropout3 = nn.Dropout(0.5)\n",
    "\n",
    "conv10 = nn.Conv1d(512, 512, kernel_size=2)\n",
    "maxpool10 = nn.MaxPool1d(2)\n",
    "        \n",
    "conv11 = nn.Conv1d(512, 1024, kernel_size=1)\n",
    "maxpool11 = nn.MaxPool1d(2)\n",
    "        \n",
    "dropout4 = nn.Dropout(0.5)\n",
    "\n",
    "\n",
    "        # Fully Connected Blocks\n",
    "flatten = nn.Flatten()\n",
    "dense1 = nn.Linear(1024, 512)\n",
    "        \n",
    "batch_norm_dense1 = nn.BatchNorm1d(512)  # BatchNorm1d for Dense1\n",
    "dropout5 = nn.Dropout(0.5)\n",
    "        \n",
    "dense2 = nn.Linear(512, 128)\n",
    "        \n",
    "batch_norm_dense2 = nn.BatchNorm1d(128)  # BatchNorm1d for Dense1\n",
    "dropout6 = nn.Dropout(0.5)\n",
    "\n",
    "dense3 = nn.Linear(128, 32)\n",
    "batch_norm_dense3 = nn.BatchNorm1d(32)  # BatchNorm1d for Dense2\n",
    "\n",
    "dense4 = nn.Linear(32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 32, 2499])\n",
      "torch.Size([32, 32, 1249])\n",
      "torch.Size([32, 64, 624])\n",
      "torch.Size([32, 64, 311])\n",
      "torch.Size([32, 128, 155])\n",
      "torch.Size([32, 128, 77])\n",
      "torch.Size([32, 128, 77])\n",
      "torch.Size([32, 256, 38])\n",
      "torch.Size([32, 256, 18])\n",
      "torch.Size([32, 256, 18])\n",
      "torch.Size([32, 512, 8])\n",
      "torch.Size([32, 512, 8])\n",
      "torch.Size([32, 512, 3])\n",
      "torch.Size([32, 1024, 1])\n",
      "torch.Size([32, 1024, 1])\n"
     ]
    }
   ],
   "source": [
    "input_dummy=torch.rand(32,1,5000)\n",
    "\n",
    "input_dummy = maxpool1(relu(bn1(conv1(input_dummy ))))\n",
    "print(input_dummy.shape)\n",
    "input_dummy= maxpool2(relu(conv2(input_dummy )))\n",
    "print(input_dummy.shape)\n",
    "input_dummy= maxpool3(relu(conv3(input_dummy )))\n",
    "print(input_dummy.shape)\n",
    "input_dummy= maxpool4(relu(conv4(input_dummy )))\n",
    "print(input_dummy.shape)\n",
    "input_dummy = maxpool5(relu(conv5(input_dummy )))\n",
    "print(input_dummy.shape)\n",
    "input_dummy =maxpool6(relu(conv6(input_dummy )))\n",
    "print(input_dummy.shape)\n",
    "input_dummy= dropout1(input_dummy )\n",
    "print(input_dummy.shape)\n",
    "input_dummy = maxpool7(relu(conv7(input_dummy )))\n",
    "print(input_dummy.shape)\n",
    "input_dummy= maxpool8(relu(conv8(input_dummy )))\n",
    "print(input_dummy.shape)\n",
    "input_dummy= dropout2(input_dummy )\n",
    "print(input_dummy.shape)\n",
    "input_dummy = maxpool9(relu(conv9(input_dummy )))\n",
    "print(input_dummy.shape)\n",
    "input_dummy = dropout3(input_dummy )\n",
    "print(input_dummy.shape)\n",
    "input_dummy = maxpool10(relu(conv10(input_dummy )))\n",
    "print(input_dummy.shape)\n",
    "input_dummy =maxpool11(relu(conv11(input_dummy )))\n",
    "print(input_dummy.shape)\n",
    "input_dummy =dropout4(input_dummy )\n",
    "print(input_dummy.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테스트용 훈련코드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Training: 100%|██████████| 545/545 [00:08<00:00, 62.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] - Validation AUROC: 0.5758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Training: 100%|██████████| 545/545 [00:09<00:00, 59.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] - Validation AUROC: 0.5848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Training: 100%|██████████| 545/545 [00:09<00:00, 58.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10] - Validation AUROC: 0.5644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Training: 100%|██████████| 545/545 [00:09<00:00, 58.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10] - Validation AUROC: 0.7671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Training: 100%|██████████| 545/545 [00:09<00:00, 58.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10] - Validation AUROC: 0.8922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Training: 100%|██████████| 545/545 [00:09<00:00, 58.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10] - Validation AUROC: 0.9473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Training: 100%|██████████| 545/545 [00:08<00:00, 62.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10] - Validation AUROC: 0.9670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Training: 100%|██████████| 545/545 [00:08<00:00, 61.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10] - Validation AUROC: 0.9622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Training: 100%|██████████| 545/545 [00:08<00:00, 61.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10] - Validation AUROC: 0.9730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Training: 100%|██████████| 545/545 [00:09<00:00, 60.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] - Validation AUROC: 0.9747\n"
     ]
    }
   ],
   "source": [
    "# 모델을 GPU로 옮기기\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Custom1DCNN2().to(device)\n",
    "\n",
    "# 손실 함수 정의 (이진 크로스 엔트로피)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 옵티마이저 선택 (Adam)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 학습 및 검증 손실과 정확도를 기록할 리스트\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "val_aurocs = []\n",
    "\n",
    "# 학습 루프 설정\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # 훈련 데이터 루프\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_preds = []\n",
    "    train_targets = []\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # 데이터를 GPU로 이동\n",
    "        optimizer.zero_grad()  # 그래디언트 초기화\n",
    "\n",
    "        # 순전파 및 역전파\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.view(-1), labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_preds.extend(torch.sigmoid(outputs).view(-1).cpu().detach().numpy())\n",
    "        train_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_accuracy = accuracy_score(train_targets, np.round(train_preds))\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # 검증 데이터 루프\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_targets = []\n",
    "    val_loss = 0.0\n",
    "    loss_check=[]\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.view(-1), labels.float())\n",
    "            val_loss += loss.item()\n",
    "            val_preds.extend(torch.sigmoid(outputs).view(-1).cpu().detach().numpy())\n",
    "            val_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = accuracy_score(val_targets, np.round(val_preds))\n",
    "    val_auroc = roc_auc_score(val_targets, val_preds)\n",
    "\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    # 에포크의 결과 출력\n",
    "    #print(f'Epoch [{epoch + 1}/{num_epochs}] - Train Loss: {train_loss:.4f} - Train Accuracy: {train_accuracy:.4f} - Validation Loss: {val_loss:.4f} - Validation Accuracy: {val_accuracy:.4f} - Validation AUROC: {val_auroc:.4f}')\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}] - Validation AUROC: {val_auroc:.4f}')\n",
    "    val_aurocs.append(val_auroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 정의 모듈을 임포트합니다.\n",
    "from annie_data_prep import create_dataloaders, load_sph_data\n",
    "from annie_cnn_model import SimpleCNN, Custom1DCNN, Custom1DCNNWithBatchNormAndDropout\n",
    "from annie_cnnlstm_model import CNNLSTMModel\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    ## 모델 시드 고정 \n",
    "    seed = 42\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # 멀티 GPU를 사용하는 경우\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "\n",
    "    # 옵튜나를 이용한 하이퍼파라미터 제안\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [64, 128])\n",
    "    num_epochs = trial.suggest_int('num_epochs', 20, 30)  # Epoch 수를 동적으로 선택\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', ['Adam', 'SGD'])\n",
    "\n",
    "\n",
    "    # 모델을 GPU로 옮기기\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = Custom1DCNN2().to(device)\n",
    "\n",
    "\n",
    "    # 손실 함수 및 옵티마이저 설정\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    if optimizer_name == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    elif optimizer_name == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    num_epochs = 100\n",
    "    #batch_size = 128\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=10, factor=0.1, verbose=True)\n",
    "    \n",
    "    train_loader, val_loader, _ = create_dataloaders(batch_size)\n",
    "    \n",
    "\n",
    "    # 하이퍼파라미터 출력\n",
    "    print(\"-\"*40)\n",
    "    print(f\">>>>> Trial {trial.number+1} Start...<<<<<\")\n",
    "    print(\"-\"*40)\n",
    "    print(f\"[Learning Rate] : {learning_rate}\")\n",
    "    print(f\"[Batch Size] : {batch_size}\")\n",
    "    print(f\"[Epochs] : {num_epochs}\")  # 수정된 부분\n",
    "    print(f\"[Optimizer] : {optimizer}\")\n",
    "    print(\"-\"*23)\n",
    "    print(\">>>>> Let's GO!!! <<<<<\")\n",
    "    print(\"-\"*23)\n",
    "\n",
    "    #print(f\"Hidden Units: {hidden_units}\")\n",
    "\n",
    "\n",
    "    # 학습 및 검증 결과 기록을 위한 사전 선언\n",
    "    model_info = {}\n",
    "\n",
    "    # 학습 및 검증 과정에서의 손실과 정확도 기록\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    train_aurocs = []  # 훈련 데이터 AUROC 기록을 위한 리스트\n",
    "    train_auprcs = []  # 훈련 데이터 AUPRC 기록을 위한 리스트\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    val_aurocs = []\n",
    "    val_auprcs = []  # AUPRC 기록을 위한 리스트 추가\n",
    "\n",
    "    \n",
    "    #best_auroc = float('-inf')  # 최고 AUROC 기록을 위한 초기값 설정\n",
    "    best_auprc = float('-inf')  # 최고 AUPRC 기록을 위한 초기값 설정\n",
    "    best_auprc_info = None  # 최고 AUPRC 값을 가진 모델의 정보를 저장할 변수\n",
    "\n",
    "    epochs_no_improve = 0\n",
    "    early_stop = False\n",
    "    patience = 20\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # 훈련 루프\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_preds, train_targets = [], []\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Trial {trial.number+1} - Epoch {epoch+1}/{num_epochs} - Training\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()  # 그래디언트 초기화\n",
    "\n",
    "            # 순전파 및 역전파\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.view(-1), labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_preds.extend(torch.sigmoid(outputs).view(-1).cpu().detach().numpy())\n",
    "            train_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_accuracy = accuracy_score(train_targets, np.round(train_preds))\n",
    "        train_auroc = roc_auc_score(train_targets, train_preds)\n",
    "        train_auprc = average_precision_score(train_targets, train_preds)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        train_aurocs.append(train_auroc)\n",
    "        train_auprcs.append(train_auprc)\n",
    "        print(f\">>> [Train] AUROC: {train_auroc:.4f} / AUPRC: {train_auprc:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "        # 검증 루프\n",
    "        model.eval()\n",
    "        val_loss, val_preds, val_targets = 0.0, [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs.view(-1), labels.float())\n",
    "                val_loss += loss.item()\n",
    "                val_preds.extend(torch.sigmoid(outputs).view(-1).cpu().detach().numpy())\n",
    "                val_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = accuracy_score(val_targets, np.round(val_preds))\n",
    "        val_auroc = roc_auc_score(val_targets, val_preds)\n",
    "        val_auprc = average_precision_score(val_targets, val_preds)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        val_aurocs.append(val_auroc)\n",
    "        val_auprcs.append(val_auprc)\n",
    "\n",
    "        print(f\">>> [Valid] AUROC: {val_auroc:.4f} / AUPRC: {val_auprc:.4f}\")\n",
    "\n",
    "\n",
    "        # 에포크 결과 기록\n",
    "        epoch_info = {\n",
    "            'train_loss': train_loss,\n",
    "            'valid_loss': val_loss,\n",
    "            'train_accuracy': train_accuracy,  \n",
    "            'valid_accuracy': val_accuracy,      \n",
    "            'train_auroc': train_auroc,\n",
    "            'valid_auroc': val_auroc,\n",
    "            'train_auprc': train_auprc,        \n",
    "            'valid_auprc': val_auprc\n",
    "        }\n",
    "        model_info[epoch + 1] = epoch_info\n",
    "\n",
    "\n",
    "        # 스케줄러 업데이트\n",
    "        scheduler.step(val_auprc)\n",
    "\n",
    "        # Early Stopping 체크 및 모델 저장\n",
    "        if val_auprc > best_auprc:\n",
    "            best_auprc = val_auprc\n",
    "            epochs_no_improve = 0\n",
    "            best_auprc_info = epoch_info  # 최고 AUPRC 값을 갱신할 때 정보 저장\n",
    "            # 최고 성능 모델 저장\n",
    "            torch.save(model.state_dict(), f'CL_trial_{trial.number+1}_best_model.pth')\n",
    "            \n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve == patience:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "    \n",
    "\n",
    "        # 전체 학습 과정의 결과를 JSON 파일로 저장\n",
    "        with open(f'CL_trial_{trial.number+1}_performance.json', 'w') as f:\n",
    "            json.dump(model_info, f, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "    # 최고 AUPRC 값을 가진 모델의 정보 출력\n",
    "    print(\"-\" * 42)\n",
    "    print(f\"< Trial {trial.number+1}'s Best Performance>\")\n",
    "    if best_auprc_info is not None:\n",
    "        items = list(best_auprc_info.items())\n",
    "        for i, (key, value) in enumerate(items):\n",
    "            print(f\"[{key}]: {value:.4f}\" + (\" <- Pick It Up!\" if i == len(items) - 1 else \"\"))\n",
    "\n",
    "    return best_auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-14 17:43:10,652] A new study created in memory with name: no-name-5f0eeb15-74a4-45e3-8f02-58bc5f718267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      ">>>>> Trial 1 Start...<<<<<\n",
      "----------------------------------------\n",
      "[Learning Rate] : 0.006329123088046764\n",
      "[Batch Size] : 64\n",
      "[Epochs] : 100\n",
      "[Optimizer] : Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.006329123088046764\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "-----------------------\n",
      ">>>>> Let's GO!!! <<<<<\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 1/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 41.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.5142 / AUPRC: 0.0734\n",
      ">>> [Valid] AUROC: 0.4828 / AUPRC: 0.0777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 2/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.5036 / AUPRC: 0.0706\n",
      ">>> [Valid] AUROC: 0.5694 / AUPRC: 0.0980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 3/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.5031 / AUPRC: 0.0724\n",
      ">>> [Valid] AUROC: 0.6087 / AUPRC: 0.1095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 4/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.5204 / AUPRC: 0.0742\n",
      ">>> [Valid] AUROC: 0.7193 / AUPRC: 0.1575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 5/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.7645 / AUPRC: 0.1974\n",
      ">>> [Valid] AUROC: 0.8958 / AUPRC: 0.3319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 6/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 41.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.8630 / AUPRC: 0.3031\n",
      ">>> [Valid] AUROC: 0.9295 / AUPRC: 0.4032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 7/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 40.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.8919 / AUPRC: 0.3342\n",
      ">>> [Valid] AUROC: 0.8632 / AUPRC: 0.2225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 8/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 41.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9221 / AUPRC: 0.4251\n",
      ">>> [Valid] AUROC: 0.9628 / AUPRC: 0.5580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 9/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9241 / AUPRC: 0.4580\n",
      ">>> [Valid] AUROC: 0.9572 / AUPRC: 0.5091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 10/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9301 / AUPRC: 0.4545\n",
      ">>> [Valid] AUROC: 0.9599 / AUPRC: 0.5435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 11/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9388 / AUPRC: 0.4897\n",
      ">>> [Valid] AUROC: 0.9440 / AUPRC: 0.4529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 12/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9429 / AUPRC: 0.4952\n",
      ">>> [Valid] AUROC: 0.9635 / AUPRC: 0.5747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 13/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 40.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9410 / AUPRC: 0.4990\n",
      ">>> [Valid] AUROC: 0.9633 / AUPRC: 0.5591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 14/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9457 / AUPRC: 0.5081\n",
      ">>> [Valid] AUROC: 0.9602 / AUPRC: 0.5147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 15/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9500 / AUPRC: 0.5184\n",
      ">>> [Valid] AUROC: 0.9648 / AUPRC: 0.5505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 16/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9521 / AUPRC: 0.5661\n",
      ">>> [Valid] AUROC: 0.9619 / AUPRC: 0.5529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 17/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 40.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9512 / AUPRC: 0.5418\n",
      ">>> [Valid] AUROC: 0.9622 / AUPRC: 0.5760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 18/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 40.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9534 / AUPRC: 0.5561\n",
      ">>> [Valid] AUROC: 0.9758 / AUPRC: 0.6542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 19/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 40.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9539 / AUPRC: 0.5579\n",
      ">>> [Valid] AUROC: 0.9782 / AUPRC: 0.6656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 20/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 40.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9577 / AUPRC: 0.5653\n",
      ">>> [Valid] AUROC: 0.9738 / AUPRC: 0.6289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 21/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 40.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9583 / AUPRC: 0.5682\n",
      ">>> [Valid] AUROC: 0.9751 / AUPRC: 0.6238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 22/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 40.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9566 / AUPRC: 0.5892\n",
      ">>> [Valid] AUROC: 0.9756 / AUPRC: 0.6438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 23/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 40.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9535 / AUPRC: 0.5751\n",
      ">>> [Valid] AUROC: 0.9748 / AUPRC: 0.6241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 24/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 40.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9608 / AUPRC: 0.6095\n",
      ">>> [Valid] AUROC: 0.9782 / AUPRC: 0.6638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 25/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9568 / AUPRC: 0.5549\n",
      ">>> [Valid] AUROC: 0.9791 / AUPRC: 0.6881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 26/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9600 / AUPRC: 0.6083\n",
      ">>> [Valid] AUROC: 0.9740 / AUPRC: 0.6611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 27/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9624 / AUPRC: 0.6194\n",
      ">>> [Valid] AUROC: 0.9755 / AUPRC: 0.6393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 28/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 40.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9635 / AUPRC: 0.6151\n",
      ">>> [Valid] AUROC: 0.9780 / AUPRC: 0.6572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 29/100 - Training: 100%|██████████| 273/273 [00:07<00:00, 38.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9634 / AUPRC: 0.6199\n",
      ">>> [Valid] AUROC: 0.9754 / AUPRC: 0.6335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 30/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9622 / AUPRC: 0.6173\n",
      ">>> [Valid] AUROC: 0.9736 / AUPRC: 0.6095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 31/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 41.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9620 / AUPRC: 0.6044\n",
      ">>> [Valid] AUROC: 0.9733 / AUPRC: 0.6212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 32/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 40.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9671 / AUPRC: 0.6176\n",
      ">>> [Valid] AUROC: 0.9780 / AUPRC: 0.6715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 33/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 41.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9664 / AUPRC: 0.6313\n",
      ">>> [Valid] AUROC: 0.9756 / AUPRC: 0.6376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 34/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 41.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9665 / AUPRC: 0.6385\n",
      ">>> [Valid] AUROC: 0.9797 / AUPRC: 0.6781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 35/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 41.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9682 / AUPRC: 0.6195\n",
      ">>> [Valid] AUROC: 0.9791 / AUPRC: 0.6726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 36/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 41.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9679 / AUPRC: 0.6380\n",
      ">>> [Valid] AUROC: 0.9786 / AUPRC: 0.6891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 37/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 41.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9696 / AUPRC: 0.6263\n",
      ">>> [Valid] AUROC: 0.9749 / AUPRC: 0.6321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 38/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 41.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9647 / AUPRC: 0.6010\n",
      ">>> [Valid] AUROC: 0.9797 / AUPRC: 0.6970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 39/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9664 / AUPRC: 0.6404\n",
      ">>> [Valid] AUROC: 0.9781 / AUPRC: 0.6817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 40/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 40.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9684 / AUPRC: 0.6272\n",
      ">>> [Valid] AUROC: 0.9779 / AUPRC: 0.6701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 41/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9697 / AUPRC: 0.6564\n",
      ">>> [Valid] AUROC: 0.9792 / AUPRC: 0.6877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 42/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9676 / AUPRC: 0.6406\n",
      ">>> [Valid] AUROC: 0.9817 / AUPRC: 0.7069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 43/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 40.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9716 / AUPRC: 0.6690\n",
      ">>> [Valid] AUROC: 0.9790 / AUPRC: 0.6758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 44/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 41.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9698 / AUPRC: 0.6486\n",
      ">>> [Valid] AUROC: 0.9699 / AUPRC: 0.5978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 45/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 41.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9713 / AUPRC: 0.6679\n",
      ">>> [Valid] AUROC: 0.9801 / AUPRC: 0.6854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 46/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9726 / AUPRC: 0.6716\n",
      ">>> [Valid] AUROC: 0.9794 / AUPRC: 0.6908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 47/100 - Training: 100%|██████████| 273/273 [00:07<00:00, 38.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9731 / AUPRC: 0.6751\n",
      ">>> [Valid] AUROC: 0.9794 / AUPRC: 0.6800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 48/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9698 / AUPRC: 0.6535\n",
      ">>> [Valid] AUROC: 0.9786 / AUPRC: 0.6567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 49/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9696 / AUPRC: 0.6552\n",
      ">>> [Valid] AUROC: 0.9813 / AUPRC: 0.6963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 50/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9734 / AUPRC: 0.6878\n",
      ">>> [Valid] AUROC: 0.9815 / AUPRC: 0.7073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 51/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9745 / AUPRC: 0.6930\n",
      ">>> [Valid] AUROC: 0.9803 / AUPRC: 0.7046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 52/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9718 / AUPRC: 0.6789\n",
      ">>> [Valid] AUROC: 0.9820 / AUPRC: 0.7173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 53/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9725 / AUPRC: 0.6833\n",
      ">>> [Valid] AUROC: 0.9806 / AUPRC: 0.6975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 54/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9762 / AUPRC: 0.6919\n",
      ">>> [Valid] AUROC: 0.9820 / AUPRC: 0.7187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 55/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9741 / AUPRC: 0.6953\n",
      ">>> [Valid] AUROC: 0.9817 / AUPRC: 0.7137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 56/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9754 / AUPRC: 0.6920\n",
      ">>> [Valid] AUROC: 0.9806 / AUPRC: 0.6907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 57/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 41.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9732 / AUPRC: 0.6915\n",
      ">>> [Valid] AUROC: 0.9838 / AUPRC: 0.7485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 58/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 40.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9739 / AUPRC: 0.7067\n",
      ">>> [Valid] AUROC: 0.9827 / AUPRC: 0.7272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 59/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9771 / AUPRC: 0.7123\n",
      ">>> [Valid] AUROC: 0.9834 / AUPRC: 0.7437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 60/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9761 / AUPRC: 0.6959\n",
      ">>> [Valid] AUROC: 0.9799 / AUPRC: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 61/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9766 / AUPRC: 0.7036\n",
      ">>> [Valid] AUROC: 0.9832 / AUPRC: 0.7365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 62/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9760 / AUPRC: 0.6984\n",
      ">>> [Valid] AUROC: 0.9820 / AUPRC: 0.7190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 63/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9764 / AUPRC: 0.7107\n",
      ">>> [Valid] AUROC: 0.9792 / AUPRC: 0.6686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 64/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9759 / AUPRC: 0.6695\n",
      ">>> [Valid] AUROC: 0.9829 / AUPRC: 0.7364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 65/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9758 / AUPRC: 0.6907\n",
      ">>> [Valid] AUROC: 0.9814 / AUPRC: 0.7035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 66/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 40.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9756 / AUPRC: 0.7184\n",
      ">>> [Valid] AUROC: 0.9825 / AUPRC: 0.7008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 67/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 40.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9754 / AUPRC: 0.7153\n",
      ">>> [Valid] AUROC: 0.9855 / AUPRC: 0.7740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 68/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9759 / AUPRC: 0.7168\n",
      ">>> [Valid] AUROC: 0.9825 / AUPRC: 0.7283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 69/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 41.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9753 / AUPRC: 0.7121\n",
      ">>> [Valid] AUROC: 0.9836 / AUPRC: 0.7532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 70/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 41.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9769 / AUPRC: 0.6967\n",
      ">>> [Valid] AUROC: 0.9821 / AUPRC: 0.7035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 71/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 41.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9769 / AUPRC: 0.7016\n",
      ">>> [Valid] AUROC: 0.9837 / AUPRC: 0.7403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 72/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 41.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9799 / AUPRC: 0.7054\n",
      ">>> [Valid] AUROC: 0.9738 / AUPRC: 0.6201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 73/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9786 / AUPRC: 0.7167\n",
      ">>> [Valid] AUROC: 0.9845 / AUPRC: 0.7445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 74/100 - Training: 100%|██████████| 273/273 [00:07<00:00, 38.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9765 / AUPRC: 0.7147\n",
      ">>> [Valid] AUROC: 0.9837 / AUPRC: 0.7410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 75/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9814 / AUPRC: 0.7569\n",
      ">>> [Valid] AUROC: 0.9815 / AUPRC: 0.7122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 76/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 41.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9785 / AUPRC: 0.7056\n",
      ">>> [Valid] AUROC: 0.9815 / AUPRC: 0.7191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 77/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 41.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9766 / AUPRC: 0.7182\n",
      ">>> [Valid] AUROC: 0.9807 / AUPRC: 0.7006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 78/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9800 / AUPRC: 0.7260\n",
      ">>> [Valid] AUROC: 0.9812 / AUPRC: 0.7037\n",
      "Epoch 00078: reducing learning rate of group 0 to 6.3291e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 79/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 40.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9809 / AUPRC: 0.7452\n",
      ">>> [Valid] AUROC: 0.9824 / AUPRC: 0.7279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 80/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 39.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9828 / AUPRC: 0.7706\n",
      ">>> [Valid] AUROC: 0.9808 / AUPRC: 0.7049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 81/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 41.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9821 / AUPRC: 0.7324\n",
      ">>> [Valid] AUROC: 0.9799 / AUPRC: 0.6948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 82/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 41.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9840 / AUPRC: 0.7623\n",
      ">>> [Valid] AUROC: 0.9807 / AUPRC: 0.7058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 83/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 41.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9821 / AUPRC: 0.7522\n",
      ">>> [Valid] AUROC: 0.9789 / AUPRC: 0.6797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 84/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 41.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9829 / AUPRC: 0.7655\n",
      ">>> [Valid] AUROC: 0.9795 / AUPRC: 0.6943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 85/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 41.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9835 / AUPRC: 0.7676\n",
      ">>> [Valid] AUROC: 0.9803 / AUPRC: 0.7070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 86/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 41.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9830 / AUPRC: 0.7468\n",
      ">>> [Valid] AUROC: 0.9818 / AUPRC: 0.7340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1 - Epoch 87/100 - Training: 100%|██████████| 273/273 [00:06<00:00, 41.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9840 / AUPRC: 0.7603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-14 17:53:32,470] Trial 0 finished with value: 0.7739925943591713 and parameters: {'learning_rate': 0.006329123088046764, 'batch_size': 64, 'num_epochs': 23, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.7739925943591713.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Valid] AUROC: 0.9801 / AUPRC: 0.6905\n",
      "Early stopping\n",
      "------------------------------------------\n",
      "< Trial 1's Best Performance>\n",
      "[train_loss]: 0.0881\n",
      "[valid_loss]: 0.0874\n",
      "[train_accuracy]: 0.9644\n",
      "[valid_accuracy]: 0.9601\n",
      "[train_auroc]: 0.9754\n",
      "[valid_auroc]: 0.9855\n",
      "[train_auprc]: 0.7153\n",
      "[valid_auprc]: 0.7740 <- Pick It Up!\n",
      "----------------------------------------\n",
      ">>>>> Trial 2 Start...<<<<<\n",
      "----------------------------------------\n",
      "[Learning Rate] : 0.005523166782844678\n",
      "[Batch Size] : 128\n",
      "[Epochs] : 100\n",
      "[Optimizer] : Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.005523166782844678\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "-----------------------\n",
      ">>>>> Let's GO!!! <<<<<\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 2 - Epoch 1/100 - Training: 100%|██████████| 137/137 [00:05<00:00, 23.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.5312 / AUPRC: 0.0732\n",
      ">>> [Valid] AUROC: 0.6404 / AUPRC: 0.1224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 2 - Epoch 2/100 - Training: 100%|██████████| 137/137 [00:06<00:00, 22.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.6768 / AUPRC: 0.1272\n",
      ">>> [Valid] AUROC: 0.7992 / AUPRC: 0.2059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 2 - Epoch 3/100 - Training: 100%|██████████| 137/137 [00:06<00:00, 22.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.7512 / AUPRC: 0.1699\n",
      ">>> [Valid] AUROC: 0.8571 / AUPRC: 0.2773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 2 - Epoch 4/100 - Training: 100%|██████████| 137/137 [00:06<00:00, 22.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.8348 / AUPRC: 0.2637\n",
      ">>> [Valid] AUROC: 0.9440 / AUPRC: 0.4629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 2 - Epoch 5/100 - Training: 100%|██████████| 137/137 [00:05<00:00, 23.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9148 / AUPRC: 0.3921\n",
      ">>> [Valid] AUROC: 0.9620 / AUPRC: 0.5532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 2 - Epoch 6/100 - Training: 100%|██████████| 137/137 [00:06<00:00, 22.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9325 / AUPRC: 0.4326\n",
      ">>> [Valid] AUROC: 0.9636 / AUPRC: 0.5605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 2 - Epoch 7/100 - Training: 100%|██████████| 137/137 [00:05<00:00, 22.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Train] AUROC: 0.9400 / AUPRC: 0.4708\n",
      ">>> [Valid] AUROC: 0.9680 / AUPRC: 0.5857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 2 - Epoch 8/100 - Training:  55%|█████▌    | 76/137 [00:03<00:02, 22.11it/s]\n",
      "[W 2023-12-14 17:54:23,416] Trial 1 failed with parameters: {'learning_rate': 0.005523166782844678, 'batch_size': 128, 'num_epochs': 29, 'optimizer': 'Adam'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_238816/3750592422.py\", line 100, in objective\n",
      "    train_loss += loss.item()\n",
      "KeyboardInterrupt\n",
      "[W 2023-12-14 17:54:23,418] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# 옵튜나 스터디 객체 생성 및 최적화 실행\u001b[39;00m\n\u001b[1;32m      2\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[1;32m      5\u001b[0m \u001b[39m# 최적의 하이퍼파라미터 출력\u001b[39;00m\n\u001b[1;32m      6\u001b[0m best_trial \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_trial\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     _optimize(\n\u001b[1;32m    452\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    453\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    454\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    455\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    456\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    457\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    458\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    459\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    460\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    461\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[32], line 100\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     97\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     98\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m--> 100\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m    101\u001b[0m train_preds\u001b[39m.\u001b[39mextend(torch\u001b[39m.\u001b[39msigmoid(outputs)\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy())\n\u001b[1;32m    102\u001b[0m train_targets\u001b[39m.\u001b[39mextend(labels\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 옵튜나 스터디 객체 생성 및 최적화 실행\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "best_trial = study.best_trial\n",
    "best_model_path = f'trial_{best_trial.number+1}_best_model.pth'\n",
    "best_performance_path = f'trial_{best_trial.number+1}_best_performance.json'\n",
    "\n",
    "print(f\"최고 성능을 보인 시도: {best_trial.number+1}\")\n",
    "print(\"최적의 하이퍼파라미터: {}\".format(study.best_trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
